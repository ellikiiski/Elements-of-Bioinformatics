{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is broadly based on preliminary work done for the article [*Quantifying massively parallel microbial growth with spatially mediated interactions*](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011585), which consists of a data science approach on analysing high-throughput growth data from [*Scan-o-matic: High-Resolution Microbial Phenomics at a Massive Scale*](https://www.g3journal.org/content/6/9/3003.short).\n",
    "Please read the paper, it is also in your reading list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the **time series**. The file `curves_raw.npy` is in a `numpy` compressed format, which means that we'll use `np.load` to read it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"curves_raw.npy\")\n",
    "n_plates, n_rows, n_columns, n_points = data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `data` now contains the time series as an `np.array`. It has 4 dimensions, which depict :\n",
    "1. the plate number\n",
    "2. the row number\n",
    "3. the column number\n",
    "4. the time point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming into a `pd.DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version of the data is very compact, but **not easily readable**. Let's turn it into a `pd.DataFrame`, so we can add better index and columns names :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nt = pd.DataFrame(\n",
    "    data    = data.reshape((n_plates * n_rows * n_columns, n_points)).T,\n",
    "    columns = pd.MultiIndex.from_product(\n",
    "        (range(n_plates), range(n_rows), range(n_columns)),\n",
    "        names = [\"plate\", \"row\", \"column\"]\n",
    "    ),\n",
    "    index   = pd.Index(range(n_points), name = \"time point\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, a specific time serie can be accessed in a similar fashion to the above `np.array` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nt[0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional calculation : distance to the border of the plate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment will require the use of specific additional data, which is the **inverse distance** of each grid point to the **closest border of the plate**.\n",
    "This calculation is here quickly done for you :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = np.empty((n_rows, n_columns))\n",
    "\n",
    "for r in range(n_rows):\n",
    "    for c in range(n_columns):\n",
    "    #   distance to top/left/bottom/right wall\n",
    "        m = min(r, c, n_rows-1 - r, n_columns-1 - c)\n",
    "        \n",
    "        dists[r, c] = 1 / (1 + m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "sns.heatmap(dists, ax = ax)\n",
    "ax.set_xlabel(\"column\")\n",
    "ax.set_ylabel(\"row\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, our data looks just like a lot of _numbers_ ; obviously, they do not really make sense when considered individually. The most common way to make sense of such a dataset is to **visualise** it graphically.\n",
    "\n",
    "Indeed, when starting to work with a new dataset the first step is very often looking at it in its entirety via various visualisations, so consider Exercise 1 as a generic \"protocol\".  The first part of this exercise will be to _plot_ the data in various ways, then later use automated methods to _regroup_ similar parts of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a. Plotting individual time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data represents **time series**, it makes sense to plot the _number of cells_ for each _time point_. In this exercise, we will do that first for a few selected populations of each plate, and then for all populations of each plate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A selection of arbitrary populations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create a plot for each plate, displaying the time series of the **locations** _(0, 0), (1, 1), (16, 24), (20, 12), (24, 40)_ and _(31, 47)_ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [(0, 0), (1, 1), (16, 24), (20, 12), (24, 40), (31, 47)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder :** The time series of the population located at _(0, 0)_ can be displayed for each plate the following way :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows = 2, ncols = 2, figsize = (16, 10))\n",
    "\n",
    "for p in range(n_plates):\n",
    "    axes[p//2, p%2].plot(\n",
    "        Nt[p, 0, 0],\n",
    "        label = f\"({0}, {0})\"\n",
    "    )\n",
    "    \n",
    "    axes[p//2, p%2].set_title(f\"plate {p+1}\")\n",
    "    axes[p//2, p%2].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the above code in the cell below, and modify it so that it displays the trajectories of all the coordinates contained in the `coords` variable :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint :** In the `for` loop iterating through the plates, nest another `for` loop iterating through the `coords` variable, and place the right function calls into that loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should observe that the populations **close to the border** behave very differently than the ones **far from the border**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding colour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add colour to the lines according to the _inverse distance_ of the populations _to the closest border_ (use a gradient from red to black if in doubt) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint 1 :** The `dists` variable maps for every location in a plate, the value you seek. So the _inverse distance_ of the location _(r, c)_ _to the closest border_ can be obtained as `dists[r, c]`.\n",
    "(Note that these values are between 0 and 1.)\n",
    "\n",
    "**Hint 2 :** _PyPlot_'s `plot` function has a `color` parametre which you can use the following way : a colour is represented as a combination of **RGB** values, which means a gradient from black to red can be obtained by varying the red component of the RGB triplet you provide to the `color` parametre. [More on colours here.](https://matplotlib.org/stable/tutorials/colors/colors.html \"Really, read the docs !\")\n",
    "A few examples :\n",
    "* **black** is _(0, 0, 0)_\n",
    "* **red** is _(1, 0, 0)_\n",
    "* **cyan** is _(0, 1, 1)_\n",
    "* **orange** is _(1, 0.5, 0)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot **all** trajectories of each plate instead of just the few arbitrary coordinates from above, with the same colour scheme :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(By the way, it is normal for this plot to take more time to generate.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note :** As this plot gets messy very fast, you may want to add transparency to the lines. Use the `alpha` parametre of the `plot` function for that (0 means fully transparent, 1 means fully opaque)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment here on how the plates differ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Plotting statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the trajectories, there is a **high diversity** on each plate. Since the plates are two-dimensional, there are two ways to display it : as a _histogram_ or as a _heatmap_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common way to summarise datasets is to use a **histogram** ; _PyPlot_ has a function called [hist](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html) which can plot a histogram for you, if provided with a 1-dimensional array of values.\n",
    "\n",
    "This function can be used the following way, if for example you want to plot a histogram of the cell numbers of each plate at coordinate _(0, 0)_ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows = 2, ncols = 2, figsize = (16, 10))\n",
    "\n",
    "for p in range(n_plates):\n",
    "    axes[p//2, p%2].hist(data[p, 0, 0], bins = 100)\n",
    "    axes[p//2, p%2].set_title(f\"plate {p+1}\")\n",
    "    axes[p//2, p%2].set_xlabel(\"N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot here for each plate a histogram of the number of cells at **time 0** (use 100 bins) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and at **the last time point** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint :** A time slice of the data is a 2x2 matrix, and you need a 1-dimensional array. Use the `reshape` method to make that transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment here on how the variance changes between the two times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment here on what the outliers at the last time point represent, on plates 2-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common way, particularly relevant for 2-dimensional data such as a grid, is to visualise it as a **heatmap** ; though _PyPlot_'s function called `imshow` can be used for that purpose, the _seaborn_ module has a [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html \"Again, read the docs ! ;)\") function which is much more powerful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot here for each plate a heatmap of the number of cells at **time 0** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and at **the last time point** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment here on how the structure of the sizes differ between the two times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c. Dimensionality reduction and clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is fortunate that we can use intuition such as the distance to the border of the plate, to distinguish different time series. But this kind of intuition does not allow us to go further into categorising the data.\n",
    "\n",
    "The standard technique for investigating data in an automated fashion is to first **reduce its dimensionality** and then to run a **clustering** algorithm, allowing us to group similar data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All plates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with dimensionality reduction ; one very common algorithm that allows that is **PCA**. We can use it on the whole data regardless of the plate, with _two components_, and project the data into the new space (read the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html \"Docs often have an example section.\") to understand how the transformation to a new space is performed) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_all = pd.DataFrame(\n",
    "    data    = PCA(n_components = 2).fit_transform(Nt.T),\n",
    "    columns = [\"component 1\", \"component 2\"],\n",
    "    index   = Nt.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a _two components_ decomposition means we decompose our set of time series as a **set of points in a 2D space**. This means, we can plot them as a _scatter plot_ ; when doing that, try to colour each point according to the plate it belongs to :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize = (16, 10))\n",
    "\n",
    "sns.scatterplot(\n",
    "    x       = \"component 1\",\n",
    "    y       = \"component 2\",\n",
    "    hue     = \"plate\",\n",
    "    data    = pca_all.reset_index(level = 0),\n",
    "    palette = sns.color_palette(n_colors = n_plates),\n",
    "    alpha   = 0.2,\n",
    "    ax      = ax\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment here on how well the plates are separable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual plates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of grouping the whole data from all plates, this time, reduce the dimensionality of each plate individually :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the decompositions for each plate on a different _scatter plot_, but this time give the colours according to the **distance to the border of the plate** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint :** You can pass the `dists` variable to the _hue_ parametre, provided you linearise it into a 1-dimensional array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment here on how well the populations are separable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE (bonus exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another very popular algorithm for dimensionality reduction is **t-SNE** ; it is substantially slower than PCA, but in turn offers often better performances. Repeat what you did with PCA but use this time t-SNE (the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) shows it works the same way than for the previous exercise) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment here on how the performances of t-SNE compete with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means (bonus exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until here we made (again !) some assumptions on how various aspects of the data can be separated or regrouped : for example, we set colours according to which plate a point belongs to, or where it is placed on a plate. But how about avoiding that step too ? \n",
    "\n",
    "There is a set of **clustering** algorithms that allow us to do that ; **K-Means** is one of them. Unfortunately, these algorithms may run quite slowly if subjected to too many dimensions ; this is why we try to reduce it beforehand.\n",
    "\n",
    "In this part of the exercise, try to run K-means on one of the sets using all plate data from before (either obtained with PCA or t-SNE), and in particular, observe how it behaves if you change the number of clusters (in the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) you can find a method analogous to the one you used in the last two exercies) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_all[\"cluster\"] = KMeans(n_clusters = 4).fit_predict(pca_all[[\"component 1\", \"component 2\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a _scatter plot_ as done above, but use the **cluster prediction** as colour :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat this with a data set where the plates are separated (use 5 clusters) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their scatter plot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment here on why the clusters look different from the distance-based ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous exercise was about _exploring_ the time series data ; making _sense_ of it. Exercise 2 on the other hand, is about **fitting** the data to a _model_ ; after all, we want to **explain** the data with a formal view, not just compare numbers and features.\n",
    "\n",
    "The model we choose is a variant of the _generalised logistic curve_ or **Richards' curve**, which is recurrent in biology :\n",
    "$$\n",
    "    N(t) = \\beta + \\frac{L_f}{(1 + \\nu e^{-k(t-t_m)})^{1/\\nu}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Training : linear fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fits for the above model are going to be difficult to perform. In order to learn to use a fitting tool called [curve_fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html), we will start by fitting a **linear model** :\n",
    "$$\n",
    "    N(t) = at + b\n",
    "$$\n",
    "The idea of a fit is to find values for the parametres $a$ and $b$ so that the model _fits_ the data we try to fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do this for plate 1 at coordinate _(16, 16)_ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.arange(n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a, b), _ = curve_fit(\n",
    "    f     = lambda t, a, b: a * t + b,\n",
    "    xdata = ts,\n",
    "    ydata = Nt[0, 16, 16]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and comparing the fit to the actual data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts, Nt[0, 16, 16], label = \"N(t)\")\n",
    "plt.plot(ts, a * ts + b, label = \"linear fit\")\n",
    "plt.title(f\"({16}, {16})\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note :** I'm providing here a _lambda_ function to the `curve_fit` function (you may want to take time to understand the concept of [anonymous function](https://en.wikipedia.org/wiki/Closure_(computer_programming)#Anonymous_functions \"Merci Wikipedia !\")), as it allows to create functions on the fly, which represents a linear model $at + b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a series of linear fits for the set of coordinates below :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [(0, 0), (1, 1), (16, 24), (20, 12), (24, 40), (31, 47)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by performing the fits, and store the obtained values into this variable :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.empty((len(coords), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint :** Use a `for` loop to iterate through the coordinates, and store the computed parametres into the `params` variable directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the linear fits against the data as done above, for every coordinate (use 2 rows and 3 columns) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment here on why the fits work well or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Upgrade : logistic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common model encountered in growth problems is the **logistic curve** :\n",
    "$$\n",
    "    N(t) = \\frac{L}{1 + e^{-k(t-t_0)}}\n",
    "$$\n",
    "This model has 3 parametres ($L$, $k$ and $t_0$) which are to be fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm(t, l, k, t0):\n",
    "    return l / (1 + np.exp(-k * (t - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts, lm(ts, l = 1, k = 0.1, t0 = 100))\n",
    "plt.title(\"example of logistic curve\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"N(t)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The catastrophic failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapt the code you wrote above in order to fit this time the `lm` function given above instead of a linear model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.empty((len(coords), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note :** There will be an _OptimizeWarning_ about the _covariance of the parametres_ not being _estimated_. Don't panic, this is expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the fitted curves for every coordinate :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the values stored in `params` (in particular the third column, the $t_0$) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data    = params,\n",
    "    columns = [\"L\", \"k\", \"t0\"],\n",
    "    index   = coords\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment here on what you observe about these failed fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain a _sigmoid_, the values of $t_0$ and $k$ have to be constrained. The solver might make better assumptions if we give hints on the values of the parametres ; one way is to set such constraints. We will choose the following constraints :\n",
    "* $L \\in ]0, \\infty[$\n",
    "* $k \\in ]0, 1]$\n",
    "* $t_0 \\in [0, \\infty[$\n",
    "\n",
    "Copy your above code, but this time providing these constraints to `curve_fit` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint :** There is a link to the documentation for `curve_fit` earlier in this exercise ; you may want to look at the `bounds` part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the fitted curves for every coordinate :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment here on those upgraded fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c. The generalised logistic curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model used from now on is **Richards' curve**, which is :\n",
    "$$\n",
    "    N(t) = \\beta + \\frac{L_f}{(1 + \\nu e^{-k(t-t_m)})^{1/\\nu}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def richards(t, beta, l_f, nu, k, t_m):\n",
    "    denom = 1 + nu * np.exp(-k * (t - t_m))\n",
    "    return beta + l_f / np.power(denom, 1/nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A 5-parametres failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the fits as above, but this time using the `richards` function and setting the bounds $]0, \\infty[$ for every parametre :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.empty((len(coords), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note :** This time you will get two _RuntimeWarning_ ; as before, don't be alarmed : this is expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the curves here :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how those values look like :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data    = params,\n",
    "    columns = [\"beta\", \"Lf\", \"nu\", \"k\", \"tm\"],\n",
    "    index   = coords\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment here on what you suppose happened this time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A 3-parametres variant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parade for such a failure is to reduce the number of parametres to fit, but it requires us to have prior knowledge on their value. Fortunately, there are two parametres in the above model that we already know :\n",
    "* $\\beta$ : the number of cells at the start of the experiment\n",
    "* $L_f$ : the difference between the numbers of cells at the start and end of the experiment\n",
    "\n",
    "In this part, we will fit only the other three parametres. Find a way to make `curve_fit` vary only the last three parametres while keeping $\\beta$ and $L_f$ to the above values (hint : try to understand the concept of _nested function_ and how the `lambda` keyword works) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.empty((len(coords), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the first two columns of `params` to the right values for $\\beta$ and $L_f$ (which you compute for each coordinate) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (r, c) in enumerate(coords):\n",
    "    n0, nf = Nt[0, r, c].iloc[[0, -1]]\n",
    "    \n",
    "    params[i, 0] = # beta\n",
    "    params[i, 1] = # Lf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now adapt the code you wrote previously, so that it calls the `richards` function inside a _lambda_ function instead of directly, allowing you to fix the $\\beta$ and $L_f$ parametres you computed by hand when calling the `richards` function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint 1 :** Your lambda function should take only the remaining parametres.\n",
    "\n",
    "**Hint 2 :** You will have to find a way to store the values returned by `curve_fit` (less then 5) into the right locations in your `params` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the fitted curves here :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment here on what you observe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to 5 parametres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting problems can become much easier if we can give some good **initial parametres** ; in the previous exercise, you fitted the last three parametres. This means that you now possess such initial parametres.\n",
    "\n",
    "Repeat what you did, but this time by providing these initial parametres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params3 = params.copy()\n",
    "params  = np.empty((len(coords), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint :** There is a link to the documentation for `curve_fit` earlier in this exercise ; you may want to look at the `p0` part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the fitted curves here :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment here on why the last part fits better now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
